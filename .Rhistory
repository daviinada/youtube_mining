text_counts
counts(as.numeric(text_counts))
text_counts
as.numeric(text_counts)
df_text_counts <- data.frame(words, counts)
counts <- as.numeric(text_counts)
df_text_counts <- data.frame(words, counts)
df_text_counts
str(df_text_counts)
df_text_counts %>%
ggplot(aes(x=words, y=counts)) %>%
geom_bar()
library(ggplot2)
words <- names(text_counts)
counts <- as.numeric(text_counts)
df_text_counts <- data.frame(words, counts)
str(df_text_counts)
df_text_counts %>%
ggplot(aes(x=words, y=counts)) %>%
geom_bar()
df_text_counts %>%
ggplot(aes(x=words, y=counts)) +
geom_bar()
df_text_counts %>%
ggplot(aes(x=words, y=counts)) +
geom_bar(stat='identity')
df_text_counts %>%
filter(counts < 50) %>%
ggplot(aes(x=words, y=counts)) +
geom_bar(stat='identity')
df_text_counts %>%
filter(counts < 50)
df_text_counts %>%
ggplot(aes(x=words, y=counts)) +
geom_bar(stat='identity')
df_text_counts
df_text_counts %>%
ggplot(aes(x=words, y=counts)) +
geom_bar(stat='identity') +
coord_flip()
words <- as.character(names(text_counts))
counts <- as.numeric(text_counts)
df_text_counts <- data.frame(words, counts)
str(df_text_counts)
df_text_counts$words <- as.character(words)
df_text_counts
str(df_text_counts)
df_text_counts %>%
ggplot(aes(x=words, y=counts)) +
geom_bar(stat='identity') +
coord_flip()
summary(df_text_counts)
df_text_counts %>%
filter(couns > 30)
df_text_counts %>%
filter(counts > 30)
str(df_text_counts)
boxplot(df_text_counts$counts)
df_text_counts %>%
filter(counts > 10)
df_text_counts %>%
filter(counts > 10) %>%
na.omit()
df_text_counts
df_text_counts %>%
filter(counts > 50)
df_text_counts <-  as.data.frame(words, counts)
df_text_counts <-  as.data.frame(words, counts)
words <- names(text_counts)
counts <- as.numeric(text_counts)
df_text_counts <-  as.data.frame(words, counts)
df_text_counts <-  cbind(words, counts)
df_text_counts$words <- as.character(words)
df_text_counts
df_text_counts <-  cbind(words, counts)
words <- names(text_counts)
counts <- as.numeric(text_counts)
counts
words
df_text_counts <-  cbind(words, counts)
df_text_counts
df_text_counts <- as.data.frame(df_text_counts)
str(df_text_counts)
df_text_counts <- data.frame(words, counts)
df_text_counts
df_text_counts$words <- as.character(words)
str(df_text_counts)
boxplot(df_text_counts$counts)
summary(df_text_counts)
df_text_counts %>%
filter(counts > 50)
subset(df_text_counts, counts > 10)
subset(df_text_counts, counts > 10) %>%
ggplot(aes(x=words, y=counts)) +
geom_bar(stat='identity') +
coord_flip()
video_id <- 'ZDRHEW8fdQk'
url_request <- paste0('http://diycaptions.com/php/get-automatic-captions-as-txt.php?id=',
video_id,
'&language=asr')
page <- read_html(url_request)
text_counts <- page %>%
html_text() %>%
strsplit('\\W+') %>%
unlist() %>%
table() %>%
sort(decreasing = TRUE)
words <- names(text_counts)
counts <- as.numeric(text_counts)
df_text_counts <- data.frame(words, counts)
df_text_counts$words <- as.character(words)
str(df_text_counts)
subset(df_text_counts, counts > 50) %>%
ggplot(aes(x=words, y=counts)) +
geom_bar(stat='identity') +
coord_flip()
subset(df_text_counts, counts > 10 & counts < 30 ) %>%
ggplot(aes(x=words, y=counts)) +
geom_bar(stat='identity') +
coord_flip()
subset(df_text_counts, counts > 20 & counts < 30 ) %>%
ggplot(aes(x=words, y=counts)) +
geom_bar(stat='identity') +
coord_flip()
# Get youtube caption
library(rvest)
library(lexiconPT)
library(ggplot2)
video_id <- 'AnkcJjzh4Bk'
url_request <- paste0('http://diycaptions.com/php/get-automatic-captions-as-txt.php?id=',
video_id,
'&language=asr')
page <- read_html(url_request)
text_counts <- page %>%
html_text() %>%
strsplit('\\W+') %>%
unlist() %>%
table() %>%
sort(decreasing = TRUE)
words <- names(text_counts)
counts <- as.numeric(text_counts)
df_text_counts <- data.frame(words, counts)
df_text_counts$words <- as.character(words)
str(df_text_counts)
boxplot(df_text_counts$counts)
summary(df_text_counts)
subset(df_text_counts, counts > 20 & counts < 30 ) %>%
ggplot(aes(x=words, y=counts)) +
geom_bar(stat='identity') +
coord_flip()
yt_oauth(client_id, key)
get_all_channel_video_stats(channel_id = 'UClu474HMt895mVxZdlIHXEA', mine = FALSE)
get_all_channel_video_stats(channel_id = 'UClu474HMt895mVxZdlIHXEA', mine = FALSE)
yt_oauth(client_id, key)
get_all_channel_video_stats(channel_id = 'UClu474HMt895mVxZdlIHXEA', mine = FALSE)
all_vid_nerdologia <- get_all_channel_video_stats(channel_id = 'UClu474HMt895mVxZdlIHXEA', mine = FALSE)
dim(all_vid_nerdologia)
client_id <- '812757213029-tt2n55mmbm4143ehdhap21e25ihp0kse.apps.googleusercontent.com'
key <- 'SblVJsud6AqXdqKpQJamZRxJ'
url_request
page <- read_html(url_request)
page
html_nodes(#well)
page %>%
html_nodes('#well')
page %>%
html_nodes('#well')
page %>%
html_nodes('#well')
page %>%
html_nodes('#.well')
page %>%
html_nodes('.well')
page %>%
html_nodes('p')
page %>%
html_nodes('br')
page %>%
html_nodes('br') %>%
html_text()
page %>%
html_nodes('.well') %>%
html_text()
page %>%
html_nodes('#text')
page %>%
html_nodes('text')
page %>%
html_nodes('.text')
all_vid_nerdologia <- get_all_channel_video_stats(channel_id = 'UClu474HMt895mVxZdlIHXEA', mine = FALSE)
client_id <- '812757213029-tt2n55mmbm4143ehdhap21e25ihp0kse.apps.googleusercontent.com'
key <- 'SblVJsud6AqXdqKpQJamZRxJ'
yt_oauth(client_id, key)
all_vid_nerdologia <- get_all_channel_video_stats(channel_id = 'UClu474HMt895mVxZdlIHXEA', mine = FALSE)
warnings()
all_vid_nerdologia
dim(all_vid_nerdologia)
saveRDS(all_vid_nerdologia, "all_vid_nerdologia.RDS")
# Get youtube caption
library(rvest)
library(lexiconPT)
library(ggplot2)
# Get youtube caption
library(rvest)
library(ggplot2)
library(dplyr)
library(tidyr)
library(lubridate)
library(dygraphs)
library(plotly)
library(tuber)
library(stringr)
library(tm)
library(wordcloud)
library(RColorBrewer)
# Get youtube caption
library(rvest)
library(ggplot2)
library(dplyr)
library(tidyr)
library(lubridate)
library(dygraphs)
library(plotly)
library(tuber)
library(stringr)
library(tm)
library(wordcloud)
library(RColorBrewer)
setwd('/home/toshi/Desktop/work_butanta/youtube_mining/')
date_split_list <- strsplit(x = as.character(all_vid_nerdologia$publication_date), split = 'T')
date_split_list <- lapply(date_split_list, function(x){ x[1] } ) %>% unlist()
setwd('/home/toshi/Desktop/work_butanta/youtube_mining/')
str(all_vid_nerdologia)
date_split_list <- strsplit(x = as.character(all_vid_nerdologia$publication_date), split = 'T')
setwd('/home/toshi/Desktop/work_butanta/youtube_mining/')
load('all_vid_nerdologia.RObj')
date_split_list <- strsplit(x = as.character(all_vid_nerdologia$publication_date), split = 'T')
date_split_list <- lapply(date_split_list, function(x){ x[1] } ) %>% unlist()
all_vid_nerdologia['publication_date'] <- date_split_list
all_vid_nerdologia$publication_date <- as.Date(all_vid_nerdologia$publication_date)
all_vid_nerdologia$viewCount <-  as.numeric(all_vid_nerdologia$viewCount)
all_vid_nerdologia$likeCount <- as.numeric(all_vid_nerdologia$likeCount)
all_vid_nerdologia$dislikeCount <- as.numeric(all_vid_nerdologia$dislikeCount)
all_vid_nerdologia$favoriteCount <- as.numeric(all_vid_nerdologia$favoriteCount)
all_vid_nerdologia$commentCount <- as.numeric(all_vid_nerdologia$commentCount)
all_vid_nerdologia[which(all_vid_nerdologia$dislikeCount == max(all_vid_nerdologia$dislikeCount)), ]
all_vid_nerdologia[which(all_vid_nerdologia$likeCount == max(all_vid_nerdologia$likeCount)), ]
all_vid_nerdologia$publication_date <- lubridate::as_datetime(all_vid_nerdologia$publication_date)
# Cleanning data title
all_vid_nerdologia$title <- gsub('\\s\\|\\s.*$', '', all_vid_nerdologia$title)
# tabela processada
all_vid_nerdologia_gather <- all_vid_nerdologia %>%
mutate(proportion_like = likeCount/ viewCount,
proportion_dislike = dislikeCount/ viewCount) %>%
gather(key= type_counts, value= counts,
c(likeCount, dislikeCount, commentCount, viewCount))
str(all_vid_nerdologia)
plot_obj <- all_vid_nerdologia_gather %>%
filter(stringr::str_detect('likeCount|dislikeCount|commentCount', type_counts)) %>%
ggplot(aes(x= publication_date, y= as.numeric(counts), col= type_counts)) +
geom_line() +
geom_point() +
scale_x_date() +
theme_bw()
str(all_vid_nerdologia)
# Plotly
all_vid_nerdologia %>%
mutate(proportion_like = likeCount / viewCount,
proportion_dislike = dislikeCount / viewCount) %>%
arrange(publication_date) %>%
plot_ly() %>%
add_trace(x = ~publication_date, y = ~viewCount,
name = 'View count', type = 'scatter',
mode ="markers+lines", text = ~paste('Video: ', title),
line = list(color = '#440154FF ', width = 4)) %>%
add_trace(x = ~publication_date, y = ~likeCount,
name = 'Like count', type = 'scatter',
mode ="markers+lines", text = ~paste('Video: ', title),
line = list(color = '#39568CFF', width = 4)) %>%
add_trace(x = ~publication_date, y = ~dislikeCount,
name = 'Dislike count', type = 'scatter',
mode = "markers+lines", text = ~paste('Video: ', title),
line = list(color = '#29AF7FFF', width = 4)) %>%
add_trace(x = ~publication_date, y = ~commentCount,
name = 'Comment count', type = 'scatter',
mode = "markers+lines", text = ~paste('Video: ', title),
line = list(color = '#FDE725FF', width = 4)) %>%
layout(xaxis = list(title = "Video publication date"),
yaxis = list (title = "Metric's count"),
font =  list(size = 16),
hovermode = 'compare')
all_vid_nerdologia_gather[which(all_vid_nerdologia_gather$title == 'Sexismo'), ]
library(RCurl)
url_request <- all_vid_nerdologia$url
url_request
html_page <- list()
html_page <- list()
html_page <- list(1:2)
html_page
html_page <- c(1:2)
html_page <- c(1:3)
html_page <- c(1:3)
if( length(html_page) == "2|4|10" ){
print('TRUE')
}else{
print('FALSE')
}
html_page <- c(1:2)
if( length(html_page) == "2|4|10" ){
print('TRUE')
}else{
print('FALSE')
}
length(html_page)
length(html_page) == "2|4|10"
html_page <- c(1:100)
if( length(html_page) == "100" ){
print('TRUE')
}else{
print('FALSE')
}
html_page <- list()
html_page <- list()
html_page <- list()
for(i in 1:length(url_request) ){
if( length(html_page) == "50" ){
save(file = 'html_page.RObj', html_page)
}
if( length(html_page) == "100" ){
save(file = 'html_page.RObj', html_page)
}
if( length(html_page) == "200" ){
save(file = 'html_page.RObj', html_page)
}
if( length(html_page) == "300" ){
save(file = 'html_page.RObj', html_page)
}
html_page[i] <- getURL(url_request[i])
Sys.sleep(15)
}
length(html_page)
html_page
url_request <- paste0('http://diycaptions.com/php/get-automatic-captions-as-txt.php?id=',  all_vid_nerdologia$id, '&language=asr')
url_request
html_page <- list()
html_page <- list()
for(i in 1:length(url_request) ){
if( length(html_page) == "50" ){
save(file = 'html_page_50.RObj', html_page)
}
if( length(html_page) == "100" ){
save(file = 'html_page.RObj', html_page)
}
if( length(html_page) == "200" ){
save(file = 'html_page.RObj', html_page)
}
if( length(html_page) == "300" ){
save(file = 'html_page.RObj', html_page)
}
html_page[i] <- getURL(url_request[i])
Sys.sleep(15)
}
length(html_page)
html_page[17]
save(file = 'html_page.RObj', html_page)
html_page[[17]]
for(i in 18:length(url_request) ){
if( length(html_page) == "50" ){
save(file = 'html_page_50.RObj', html_page)
}
if( length(html_page) == "100" ){
save(file = 'html_page.RObj', html_page)
}
if( length(html_page) == "200" ){
save(file = 'html_page.RObj', html_page)
}
if( length(html_page) == "300" ){
save(file = 'html_page.RObj', html_page)
}
html_page[i] <- getURL(url_request[i])
Sys.sleep(15)
}
length(html_page)
save(file = 'html_page.RObj', html_page)
html_page[[136]]
for(i in 137:length(url_request) ){
if( length(html_page) == "50" ){
save(file = 'html_page_50.RObj', html_page)
}
if( length(html_page) == "100" ){
save(file = 'html_page.RObj', html_page)
}
if( length(html_page) == "200" ){
save(file = 'html_page.RObj', html_page)
}
if( length(html_page) == "300" ){
save(file = 'html_page.RObj', html_page)
}
html_page[i] <- getURL(url_request[i])
Sys.sleep(30)
}
length(html_page)
save(file = 'html_page.RObj', html_page)
html_page[[273]]
save(file = 'html_page.RObj', html_page)
save(file = 'html_page.RObj', html_page)
length(html_page)
for(i in 274:length(url_request) ){
if( length(html_page) == "50" ){
save(file = 'html_page_50.RObj', html_page)
}
if( length(html_page) == "100" ){
save(file = 'html_page.RObj', html_page)
}
if( length(html_page) == "200" ){
save(file = 'html_page.RObj', html_page)
}
if( length(html_page) == "300" ){
save(file = 'html_page_300.RObj', html_page)
}
html_page[i] <- getURL(url_request[i])
Sys.sleep(30)
}
length(html_page)
html_page[[343]]
save(file = 'html_page.RObj', html_page)
for(i in 344:length(url_request) ){
if( length(html_page) == "50" ){
save(file = 'html_page_50.RObj', html_page)
}
if( length(html_page) == "100" ){
save(file = 'html_page.RObj', html_page)
}
if( length(html_page) == "200" ){
save(file = 'html_page.RObj', html_page)
}
if( length(html_page) == "300" ){
save(file = 'html_page_300.RObj', html_page)
}
html_page[i] <- getURL(url_request[i])
Sys.sleep(30)
}
save(file = 'html_page.RObj', html_page)
save(file = 'html_page.RObj', html_page)
length(html_page)
html_page_text <- lapply(html_page, function(x){ html_text(x)  })
html_page[[1]]
html_page[[1:2]]
html_page[1:2]
html_page_text <- lapply(html_page[1:2], function(x){ html_text(x)  })
html_page[[12]]
html_page[[22]]
html_page[[2]]
html_page[[2]] %>%
html_nodes('div')
str_split(html_page[[1]], '<br><br>')
str_split(html_page[[1]], '<br><br>', n = 2)
strsplit(html_page[[1]], '<br><br>')
strsplit(html_page[[1]], '<br><br>')
strsplit(html_page[[1]], '<br><br>')[2]
strsplit(html_page[[1]], '<br><br>')[[2]]
strsplit(html_page[[1]], '<br><br>')[[1]]
html_page[[1]]
strsplit(html_page[[2]], '<br><br>')
strsplit(html_page[[2]], '<br><br>')
strsplit(html_page[[2]], '<br><br>')[2]
strsplit(html_page[[2]], '<br><br>')[[2]]
strsplit(html_page[[2]], '<br><br>')
strsplit(html_page[[2]], '<br><br>')
strsplit(html_page[[2]], '<br><br>')[2]
strsplit(html_page[[2]], '<br><br>')[[2]]
strsplit(html_page[[2]], '<br><br>')[[1]]
strsplit(html_page[[2]], '<br><br>')[[1]][2]
strsplit(html_page[[2]], '<br><br>')[[2]][2]
strsplit(html_page[[2]], '<br><br>')[[1]][2]
strsplit(html_page[[1:2]], '<br><br>')[[1]][2]
html_page[1:2]
lapply(html_page[1:2], function(x){
strsplit(x[[1]], '<br><br>')[[1]][2]
})
lapply(html_page[1:3], function(x){
strsplit(x[[1]], '<br><br>')[[1]][2]
})
lapply(html_page[1:3], function(x){
split_1 <- strsplit(x[[1]], '<br><br>')[[1]][2]
strsplit(split_1[[1]], '\t\t</div>')[[1]][1]
})
html_page_text <- lapply(html_page, function(x){
split_1 <- strsplit(x[[1]], '<br><br>')[[1]][2]
strsplit(split_1[[1]], '\t\t</div>')[[1]][1]
})
length(html_page_text)
html_page_text[350]
html_page_text <- lapply(html_page, function(x){
split_1 <- strsplit(x[[1]], '<br><br>')[[1]][2]
strsplit(split_1[[1]], '\t\t</div>')[[1]][1]
})
all_vid_nerdologia$title
all_vid_nerdologia$id
text_df <- data.frame(doc_id = all_vid_nerdologia$id, text = unlist(html_page_text), stringsAsFactors = FALSE , drop=FALSE)
str(text_df)
text_corpus <- Corpus(DataframeSource(text_df))
text_corpus_filtered <- text_corpus %>%
tm_map(stripWhitespace)  %>%
tm_map(removePunctuation) %>%
tm_map(removeNumbers)   %>%
tm_map(removeWords, c(stopwords("portuguese"))) %>%
tm_map(removeNumbers) %>%
tm_map(stripWhitespace) %>%
tm_map(content_transformer(tolower))
inspect(text_corpus_filtered)
dim(text_corpus_filtered)
